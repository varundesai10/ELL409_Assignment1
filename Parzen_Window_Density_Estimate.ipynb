{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('health_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.to_numpy()[:, :3]\n",
    "Y = data.to_numpy()[:, 3]\n",
    "split = 0.8 #using 70:30 split, random each time\n",
    "train_samples = np.random.choice(X.shape[0], int(split*X.shape[0]))\n",
    "test_samples = np.array([i for i in range(X.shape[0]) if i not in list(train_samples)])\n",
    "\n",
    "X_train = X[[train_samples]]\n",
    "Y_train = Y[[train_samples]]\n",
    "\n",
    "X_test = X[[test_samples]]\n",
    "Y_test = Y[[test_samples]]\n",
    "\n",
    "X_0 = X_train[Y_train == 0]\n",
    "X_1 = X_train[Y_train == 1]\n",
    "\n",
    "X_test_0 = X_test[Y_test == 0]\n",
    "X_test_1 = X_test[Y_test==1]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_00 = data[data['category'] == 0].to_numpy()[:, :3]\n",
    "X_11 = data[data['category'] == 1].to_numpy()[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = plt.hist(X_00[:, 0], bins=40, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2 = plt.hist(X_00[:, 1], bins=30, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = plt.hist(X_00[:, 2], bins=30, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist11 = plt.hist(X_11[:, 0], bins=20, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist12 = plt.hist(X_11[:, 1], bins=30, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist13 = plt.hist(X_11[:, 2], bins=40, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hypercube_Kernel\n",
    "def hypercube_kernel(h, x, x_i):\n",
    "    assert (x.shape == x_i.shape)\n",
    "    return (x - x_i) / (h)\n",
    "\n",
    "\n",
    "#Window_function   \n",
    "def parzen_window_func(x_vec):\n",
    "    for row in x_vec:\n",
    "        if np.abs(row) > (1/2):\n",
    "            return 0\n",
    "        return 1\n",
    "\n",
    "#Estimation\n",
    "def parzen_estimation_for_hyper_cube(x_samples, point_x, h, d):\n",
    "    dimensions = x_samples.shape[1]\n",
    "    assert (len(point_x) == dimensions)\n",
    "    k_n = 0\n",
    "    for row in x_samples:\n",
    "        x_i = hypercube_kernel(h=h, x=point_x, x_i=row)\n",
    "        k_n += parzen_window_func(x_i)\n",
    "    return (k_n / len(x_samples)) / (h**d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_multivariate_gauss(x, mu, cov):\n",
    "    assert(mu.shape[0] > mu.shape[1])\n",
    "    assert(x.shape[0] > x.shape[1])\n",
    "    assert(cov.shape[0] == cov.shape[1])\n",
    "    assert(mu.shape[0] == cov.shape[0])\n",
    "    assert(mu.shape[0] == x.shape[0])\n",
    "    part1 = 1 / ( ((2* np.pi)**(len(mu)/2)) * (np.linalg.det(cov)**(1/2)) )\n",
    "    part2 = (-1/2) * ((x-mu).T.dot(np.linalg.inv(cov))).dot((x-mu))\n",
    "    return float(part1 * np.exp(part2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian_kernel_and_window_function\n",
    "def gaussian_window_function(cov, x, x_i):\n",
    "    assert (x.shape == x_i.shape)\n",
    "    assert(cov.shape[0] == cov.shape[1])\n",
    "    assert(x_i.shape[0] == cov.shape[0])\n",
    "    return pdf_multivariate_gauss(x, x_i,cov)\n",
    "\n",
    "\n",
    "#Estimation\n",
    "def parzen_estimation_for_gaussian(x_samples, point_x, cov):\n",
    "    prob = 0.0\n",
    "    for row in x_samples:\n",
    "        prob += gaussian_window_function(cov,point_x,x_i)\n",
    "    return k_n "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prior calculation\n",
    "P = [float(len(X_0))/ float(len(X_0) + len(X_1)) ,float(len(X_1))/ float(len(X_0) + len(X_1)) ]\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculation of posterior\n",
    "def posterior(X_train_0,X_train_1, data, P,h,d):\n",
    "    prob = np.zeros(2, dtype = np.float64)\n",
    "    class_probabilities = [parzen_estimation_for_hyper_cube(X_train_0, data, h, d), parzen_estimation_for_hyper_cube(X_train_1, data, h, d)]\n",
    "    \n",
    "    #print(probabilities)\n",
    "    for i in range(2):\n",
    "        prob[i] = class_probabilities[i]*P[i]\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(data, X_train_0, X_train_1,P, h, Th):\n",
    "    Probabilities = posterior(X_train_0, X_train_1, data, P, h, X_train.shape[1])\n",
    "    Probabilities = Probabilities/sum(Probabilities)\n",
    "    #print(Probabilities)\n",
    "    if Probabilities[1] > Th:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing accuracy on test data.\n",
    "C = np.zeros((2,2)) #[[]]\n",
    "for i in range((X_test_0.shape[0])):\n",
    "    y_pred = prediction(X_test_0[i], X_0,X_1, P, 1, 0.5)\n",
    "    C[y_pred, 0] += 1\n",
    "for i in range((X_test_1.shape[0])):\n",
    "    y_pred = prediction(X_test_1[i], X_0, X_1, P, 1, 0.5)\n",
    "    C[y_pred, 1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (C[0,0] + C[1,1])/np.sum(C)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_predictivity = (C[0,0])/(C[0,0] + C[0,1])\n",
    "neg_predictivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (C[1,1])/(C[1,0] + C[1,1])\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall = (C[0,0])/(C[0,0] + C[1,0])\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Specificity = (C[1,1])/(C[0,1] + C[1,1])\n",
    "Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "Precision = []\n",
    "Recall = []\n",
    "ACC = []\n",
    "F1_score = []\n",
    "kk = range(1,300)\n",
    "for h in np.linspace(0.01,5,5000):\n",
    "    C = np.zeros((2,2)) #[[]]\n",
    "    for i in range((X_test_0.shape[0])):\n",
    "        y_pred = prediction(X_test_0[i], X_0,X_1, P, h, 0.5)\n",
    "        C[y_pred, 0] += 1\n",
    "    for i in range((X_test_1.shape[0])):\n",
    "        y_pred = prediction(X_test_1[i], X_0, X_1, P, h, 0.5)\n",
    "    C[y_pred, 1] += 1\n",
    "    acc = (C[0,0] + C[1,1])/np.sum(C) \n",
    "    pr = C[1,1]/(C[1,1] + C[0,1])\n",
    "    rec = C[1,0]/(C[1,0] + C[0,0])\n",
    "    f1 = 2*(pr*rec)/(pr + rec)\n",
    "    Precision.append(pr)\n",
    "    Recall.append(rec)\n",
    "    F1_score.append(f1)\n",
    "    ACC.append(acc)\n",
    "#plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC curve');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
